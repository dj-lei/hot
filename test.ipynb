{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "num_epochs = 1000\n",
    "batch_size = 32\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_and_resize(filename, label):\n",
    "    image_string = tf.io.read_file(filename)            # 读取原始文件\n",
    "    image_decoded = tf.image.decode_jpeg(image_string)  # 解码JPEG图片\n",
    "    image_resized = tf.image.resize(image_decoded, [224, 224]) / 255.0\n",
    "    return image_resized, label\n",
    "\n",
    "data_text = pd.read_csv('train_data.csv')\n",
    "# 构建训练数据集\n",
    "train_filenames = tf.constant([filename for filename in list(data_text.path.values)])\n",
    "train_labels = list(data_text.page_num.values)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "train_dataset = train_dataset.map(\n",
    "    map_func=_decode_and_resize, \n",
    "    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# 取出前buffer_size个数据放入buffer，并从其中随机采样，采样后的数据用后续数据替换\n",
    "train_dataset = train_dataset.shuffle(buffer_size=500)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_fine_tune = tf.keras.models.Sequential()\n",
    "\n",
    "resnet50_fine_tune.add(tf.keras.applications.ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet'))\n",
    "resnet50_fine_tune.add(tf.keras.layers.Dense(48, activation = 'softmax'))\n",
    "resnet50_fine_tune.layers[0].trainable = False\n",
    "# resnet50_fine_tune.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=['accuracy'])\n",
    "resnet50_fine_tune.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    ")\n",
    "resnet50_fine_tune.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet50_fine_tune.fit(train_dataset, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "from torchvision.models.resnet import Bottleneck, BasicBlock, ResNet\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from model.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_net = ResidualNet()\n",
    "image_net.eval()\n",
    "image_net = image_net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_net = RoBertaChinese()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    best_seller = pd.read_csv('best_seller.csv')\n",
    "    image_vectors = []\n",
    "    text_vectors = []\n",
    "    for i in range(0, len(best_seller)):\n",
    "        image_path = 'data/best_seller/'+best_seller['id'][i]+'.jpg'\n",
    "        image_space_vector = get_image_space_vector(image_path, image_net, 'avg')\n",
    "        text_space_vector = get_text_space_vector(best_seller['title'][i], text_net.tokenizer, text_net.model).tolist()\n",
    "        image_vectors.append(image_space_vector)\n",
    "        text_vectors.append(text_space_vector)\n",
    "    best_seller['image_vectors'] = pd.Series(image_vectors)\n",
    "    best_seller['text_vectors'] = pd.Series(text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    source_goods = pd.read_csv('source_goods.csv')\n",
    "    image_vectors = []\n",
    "    text_vectors = []\n",
    "    for i in range(0, len(source_goods)):\n",
    "        image_path = 'data/source_goods/'+source_goods['id'][i]+'.jpg'\n",
    "        image_space_vector = get_image_space_vector(image_path, image_net, 'avg')\n",
    "        text_space_vector = get_text_space_vector(source_goods['title'][i], text_net.tokenizer, text_net.model).tolist()\n",
    "        image_vectors.append(image_space_vector)\n",
    "        text_vectors.append(text_space_vector)\n",
    "    source_goods['image_vectors'] = pd.Series(image_vectors)\n",
    "    source_goods['text_vectors'] = pd.Series(text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "source_goods['image_mean_cosine'] = 0\n",
    "list_best_seller_vectors = best_seller.image_vectors.values\n",
    "for i in range(0, len(source_goods)):\n",
    "    mean_cosine = get_good_mean_cosine(source_goods['image_vectors'][i], list_best_seller_vectors)\n",
    "    source_goods.loc[i, 'image_mean_cosine'] = mean_cosine\n",
    "    \n",
    "source_goods['text_mean_cosine'] = 0\n",
    "list_best_seller_vectors = best_seller.text_vectors.values\n",
    "for i in range(0, len(source_goods)):\n",
    "    mean_cosine = get_good_mean_cosine(source_goods['text_vectors'][i], list_best_seller_vectors)\n",
    "    source_goods.loc[i, 'text_mean_cosine'] = mean_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = source_goods.sort_values(by=['image_mean_cosine'],ascending=False).reset_index(drop=True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = temp.loc[:20,:]\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(0,len(temp1)):\n",
    "    pic = Image.open('data/source_goods/'+temp1['id'][i]+'.jpg')\n",
    "    pic = pic.convert('RGB')\n",
    "    pic.save('data/test/'+temp1['id'][i]+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import argparse\n",
    "from spider.spider import *\n",
    "from db.db import *\n",
    "\n",
    "    \n",
    "firefox_profile = \"/home/ml/.mozilla/firefox/0k5sh6ex.default\"\n",
    "crawl_config = \"config/crawl.cfg\"\n",
    "redis_config = '172.17.0.2:6379:1'\n",
    "mysql_config = '172.17.0.3:root:123456:hot'\n",
    "\n",
    "cf = configparser.ConfigParser()\n",
    "cf.read(crawl_config)\n",
    "\n",
    "redis_ctrl = RedisCtrl(redis_config.split(':'))\n",
    "mysql_ctrl = MysqlCtrl(mysql_config.split(':'))\n",
    "\n",
    "# # Is there any key words in redis yet\n",
    "# key_words = '连衣裙'\n",
    "\n",
    "# # Secend crawl the corresponding key word of platform of best seller\n",
    "# best_seller_data = pd.DataFrame()\n",
    "# spider_sing_page = SinglePageSpider(firefox_profile)\n",
    "# for platform, url in cf.items('best_seller_search_url'):\n",
    "#     url = url.replace(re.findall('&q=(.*?)&',url)[0],key_words)\n",
    "#     cfg = cf.items(platform + '_parse_links')\n",
    "#     cfg.pop(0)\n",
    "#     cfg.pop(0)\n",
    "#     best_seller_data = best_seller_data.append(spider_sing_page.run(url, dict(cfg))).reset_index(drop=True)\n",
    "# spider_sing_page.close()\n",
    "\n",
    "# # Third crawl the corresponding key word of platform of source goods\n",
    "# source_goods = pd.DataFrame()\n",
    "# spider_multi_pages = MultiPageSpider(firefox_profile)\n",
    "# for platform, url in cf.items('source_goods_url'):\n",
    "#     url = url.replace(re.findall('\\?so=(.*?)&',url)[0],key_words)\n",
    "#     cfg = cf.items(platform + '_parse_links')\n",
    "#     source_goods = source_goods.append(spider_multi_pages.run(url, dict(cfg))).reset_index(drop=True)\n",
    "# spider_multi_pages.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>shop</th>\n",
       "      <th>images_url_attribute</th>\n",
       "      <th>product_url_attribute</th>\n",
       "      <th>page_num</th>\n",
       "      <th>crawl_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>009494d8-9473-496f-9fc6-33ce6fcbaa64</td>\n",
       "      <td>实拍大码女2020早新胖妹显瘦连衣裙内搭打底小香风针织开衫两件套</td>\n",
       "      <td>50.00</td>\n",
       "      <td>宜蔓大码</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i4/6744267...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=116409585&amp;sp...</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>009f4c6d-223e-404e-b1c0-8e17fd1b9f01</td>\n",
       "      <td>实拍现货大码微胖遮肚裙子显瘦秋季新款女装长袖胖mm中长款连衣裙</td>\n",
       "      <td>50.00</td>\n",
       "      <td>汇美大码女装</td>\n",
       "      <td>https://img01-gms.17zwd.com/imgextra/61445306/...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=117196679&amp;sp...</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015236d7-36f0-406e-9b1e-f9745d6904ab</td>\n",
       "      <td>印花香云纱真丝连衣裙2020春夏季新款气质修身拼接桑蚕丝旗袍裙子</td>\n",
       "      <td>65.00</td>\n",
       "      <td>艾瑞衣阁</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i2/2532585...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=114577444&amp;sp...</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02357cae-1468-441c-9a13-e4daef970e4f</td>\n",
       "      <td>实拍2775#裙子秋女新款连衣裙碎花雪纺超仙收腰沙滩大摆超长裙</td>\n",
       "      <td>63.00</td>\n",
       "      <td>女人花旗舰店</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i3/8369987...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=115886504&amp;sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02b19dd7-f545-460b-954b-d5e10529081b</td>\n",
       "      <td>实拍改良版旗袍连衣裙2020秋装新款高开叉中式刺绣民族风唐装日常</td>\n",
       "      <td>73.00</td>\n",
       "      <td>欧丽姿实拍服饰</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i4/2048402...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=116964113&amp;sp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>ff67a71e-1c52-4612-8f6f-bb9e38ee96fc</td>\n",
       "      <td>实拍！秋冬新款银狐绒加绒加厚连衣裙孕妇宽松休闲荷叶边连帽裙女</td>\n",
       "      <td>52.00</td>\n",
       "      <td>孕味坊</td>\n",
       "      <td>https://static-new.17zwd.com/assets/source/sta...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=117195741&amp;sp...</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>ff70325e-b164-4586-a2f8-c91fd3b2b6bb</td>\n",
       "      <td>实拍现货 针织打底衫+水貂毛背心裙连衣裙两件套装女2020秋冬季新</td>\n",
       "      <td>79.00</td>\n",
       "      <td>乐颜</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i1/1771533...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=117196908&amp;sp...</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>ffab4597-e728-4f79-93bc-ad410eb542f5</td>\n",
       "      <td>v领雪纺碎花连衣裙女夏2020新款za法式复古显瘦显高气质高腰长裙</td>\n",
       "      <td>68.00</td>\n",
       "      <td>宜蔓服饰</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i2/2256175...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=115461043&amp;sp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>ffc1a633-2e64-443d-9434-ba423e17b090</td>\n",
       "      <td>实拍现货 针织连衣裙女秋冬季2020年新款毛衣裙超仙内搭打底裙</td>\n",
       "      <td>68.00</td>\n",
       "      <td>乐颜</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i2/1771533...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=117194786&amp;sp...</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>ffee5ca4-2d04-4bbf-9d7e-7a1e73273f68</td>\n",
       "      <td>实拍连衣裙2020年新款气质显瘦中长款拼接a字女人裙子减龄中长裙</td>\n",
       "      <td>35.00</td>\n",
       "      <td>欣欣网络服饰</td>\n",
       "      <td>https://img.alicdn.com/bao/uploaded/i4/2870315...</td>\n",
       "      <td>https://gz.17zwd.com/item.htm?GID=114790602&amp;sp...</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-18 05:25:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id                              title  \\\n",
       "0    009494d8-9473-496f-9fc6-33ce6fcbaa64   实拍大码女2020早新胖妹显瘦连衣裙内搭打底小香风针织开衫两件套   \n",
       "1    009f4c6d-223e-404e-b1c0-8e17fd1b9f01    实拍现货大码微胖遮肚裙子显瘦秋季新款女装长袖胖mm中长款连衣裙   \n",
       "2    015236d7-36f0-406e-9b1e-f9745d6904ab   印花香云纱真丝连衣裙2020春夏季新款气质修身拼接桑蚕丝旗袍裙子   \n",
       "3    02357cae-1468-441c-9a13-e4daef970e4f    实拍2775#裙子秋女新款连衣裙碎花雪纺超仙收腰沙滩大摆超长裙   \n",
       "4    02b19dd7-f545-460b-954b-d5e10529081b   实拍改良版旗袍连衣裙2020秋装新款高开叉中式刺绣民族风唐装日常   \n",
       "..                                    ...                                ...   \n",
       "395  ff67a71e-1c52-4612-8f6f-bb9e38ee96fc     实拍！秋冬新款银狐绒加绒加厚连衣裙孕妇宽松休闲荷叶边连帽裙女   \n",
       "396  ff70325e-b164-4586-a2f8-c91fd3b2b6bb  实拍现货 针织打底衫+水貂毛背心裙连衣裙两件套装女2020秋冬季新   \n",
       "397  ffab4597-e728-4f79-93bc-ad410eb542f5  v领雪纺碎花连衣裙女夏2020新款za法式复古显瘦显高气质高腰长裙   \n",
       "398  ffc1a633-2e64-443d-9434-ba423e17b090    实拍现货 针织连衣裙女秋冬季2020年新款毛衣裙超仙内搭打底裙   \n",
       "399  ffee5ca4-2d04-4bbf-9d7e-7a1e73273f68   实拍连衣裙2020年新款气质显瘦中长款拼接a字女人裙子减龄中长裙   \n",
       "\n",
       "     price     shop                               images_url_attribute  \\\n",
       "0    50.00     宜蔓大码  https://img.alicdn.com/bao/uploaded/i4/6744267...   \n",
       "1    50.00   汇美大码女装  https://img01-gms.17zwd.com/imgextra/61445306/...   \n",
       "2    65.00     艾瑞衣阁  https://img.alicdn.com/bao/uploaded/i2/2532585...   \n",
       "3    63.00   女人花旗舰店  https://img.alicdn.com/bao/uploaded/i3/8369987...   \n",
       "4    73.00  欧丽姿实拍服饰  https://img.alicdn.com/bao/uploaded/i4/2048402...   \n",
       "..     ...      ...                                                ...   \n",
       "395  52.00      孕味坊  https://static-new.17zwd.com/assets/source/sta...   \n",
       "396  79.00       乐颜  https://img.alicdn.com/bao/uploaded/i1/1771533...   \n",
       "397  68.00     宜蔓服饰  https://img.alicdn.com/bao/uploaded/i2/2256175...   \n",
       "398  68.00       乐颜  https://img.alicdn.com/bao/uploaded/i2/1771533...   \n",
       "399  35.00   欣欣网络服饰  https://img.alicdn.com/bao/uploaded/i4/2870315...   \n",
       "\n",
       "                                 product_url_attribute  page_num  \\\n",
       "0    https://gz.17zwd.com/item.htm?GID=116409585&sp...         2   \n",
       "1    https://gz.17zwd.com/item.htm?GID=117196679&sp...         3   \n",
       "2    https://gz.17zwd.com/item.htm?GID=114577444&sp...         2   \n",
       "3    https://gz.17zwd.com/item.htm?GID=115886504&sp...         0   \n",
       "4    https://gz.17zwd.com/item.htm?GID=116964113&sp...         1   \n",
       "..                                                 ...       ...   \n",
       "395  https://gz.17zwd.com/item.htm?GID=117195741&sp...         2   \n",
       "396  https://gz.17zwd.com/item.htm?GID=117196908&sp...         3   \n",
       "397  https://gz.17zwd.com/item.htm?GID=115461043&sp...         1   \n",
       "398  https://gz.17zwd.com/item.htm?GID=117194786&sp...         3   \n",
       "399  https://gz.17zwd.com/item.htm?GID=114790602&sp...         3   \n",
       "\n",
       "             crawl_time  \n",
       "0   2020-10-18 05:25:07  \n",
       "1   2020-10-18 05:25:07  \n",
       "2   2020-10-18 05:25:07  \n",
       "3   2020-10-18 05:25:07  \n",
       "4   2020-10-18 05:25:07  \n",
       "..                  ...  \n",
       "395 2020-10-18 05:25:07  \n",
       "396 2020-10-18 05:25:07  \n",
       "397 2020-10-18 05:25:07  \n",
       "398 2020-10-18 05:25:07  \n",
       "399 2020-10-18 05:25:07  \n",
       "\n",
       "[400 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysql_ctrl.load('source_goods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
